{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa01644",
   "metadata": {},
   "source": [
    "# Prediksi Tingkat Kemiskinan di Indonesia\n",
    "**Deskripsi:** Notebook ini membangun model prediksi tingkat kemiskinan dengan menggabungkan data klasifikasi kemiskinan, data sosial-ekonomi 2021, dan indikator pendidikan provinsi 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd47fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ac026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# optional / advanced\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    shap = None\n",
    "\n",
    "print(\"Libraries imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc7afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected paths:\n",
      "data/klasifikasi_kemiskinan.csv\n",
      "data/socio_economic.csv\n",
      "data/data_pendidikan.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data\"  # folder tempat CSV\n",
    "Poverty_path = os.path.join(DATA_DIR, \"klasifikasi_kemiskinan.csv\")\n",
    "Socio_path   = os.path.join(DATA_DIR, \"socio_economic.csv\")\n",
    "Edu_path     = os.path.join(DATA_DIR, \"data_pendidikan.csv\")\n",
    "\n",
    "print(\"Expected paths:\")\n",
    "print(Poverty_path)\n",
    "print(Socio_path)\n",
    "print(Edu_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaba5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_csv(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"File not found: {path}\")\n",
    "        return None\n",
    "    encodings = ['utf-8', 'latin1', 'cp1252']\n",
    "    for e in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=e)\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as ex:\n",
    "        print(f\"Failed to read {path}: {ex}\")\n",
    "        return None\n",
    "\n",
    "def normalize_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "                  .str.lower()\n",
    "                  .str.replace(' ', '_')\n",
    "                  .str.replace('-', '_')\n",
    "                  .str.replace('\\\\n', '_')\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d698ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: data/klasifikasi_kemiskinan.csv\n",
      "File not found: data/socio_economic.csv\n",
      "File not found: data/data_pendidikan.csv\n",
      "poverty -> NOT LOADED\n",
      "socio -> NOT LOADED\n",
      "edu -> NOT LOADED\n"
     ]
    }
   ],
   "source": [
    "poverty = safe_read_csv(Poverty_path)\n",
    "socio   = safe_read_csv(Socio_path)\n",
    "edu     = safe_read_csv(Edu_path)\n",
    "\n",
    "for name, df in [('poverty', poverty), ('socio', socio), ('edu', edu)]:\n",
    "    if df is None:\n",
    "        print(f\"{name} -> NOT LOADED\")\n",
    "    else:\n",
    "        print(f\"{name} -> loaded, shape: {df.shape}\")\n",
    "        display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b367d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample columns (poverty): []\n",
      "Sample columns (socio): []\n",
      "Sample columns (edu): []\n"
     ]
    }
   ],
   "source": [
    "if poverty is not None:\n",
    "    poverty = normalize_columns(poverty)\n",
    "if socio is not None:\n",
    "    socio = normalize_columns(socio)\n",
    "if edu is not None:\n",
    "    edu = normalize_columns(edu)\n",
    "\n",
    "print(\"Sample columns (poverty):\", (poverty.columns.tolist()[:30] if poverty is not None else []))\n",
    "print(\"Sample columns (socio):\", (socio.columns.tolist()[:30] if socio is not None else []))\n",
    "print(\"Sample columns (edu):\", (edu.columns.tolist()[:30] if edu is not None else []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8888ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible join cols poverty: []\n",
      "Possible join cols socio: []\n",
      "Possible join cols edu: []\n"
     ]
    }
   ],
   "source": [
    "def find_possible_join_cols(df):\n",
    "    candidates = ['provinsi','province','kode_prov','kode_provinsi','nama_provinsi','nama_prov','kabupaten','district','prov']\n",
    "    found = [c for c in df.columns if any(k in c for k in candidates)]\n",
    "    return found\n",
    "\n",
    "print(\"Possible join cols poverty:\", find_possible_join_cols(poverty) if poverty is not None else [])\n",
    "print(\"Possible join cols socio:\", find_possible_join_cols(socio) if socio is not None else [])\n",
    "print(\"Possible join cols edu:\", find_possible_join_cols(edu) if edu is not None else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40343de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_and_merge(poverty, socio, edu, join_name='provinsi'):\n",
    "    dfs = [poverty, socio, edu]\n",
    "    # attempt to rename first matching join col to 'provinsi' in each df\n",
    "    candidates = ['provinsi','province','nama_prov','nama_provinsi','prov']\n",
    "    for df in dfs:\n",
    "        if df is None:\n",
    "            continue\n",
    "        found = None\n",
    "        for c in df.columns:\n",
    "            for cand in candidates:\n",
    "                if cand in c:\n",
    "                    found = c\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if found:\n",
    "            df.rename(columns={found: join_name}, inplace=True)\n",
    "    # now try full merge on provinsi\n",
    "    merged = poverty.copy() if poverty is not None else None\n",
    "    if merged is not None and socio is not None and 'provinsi' in merged.columns and 'provinsi' in socio.columns:\n",
    "        merged = merged.merge(socio, on='provinsi', how='left')\n",
    "    elif merged is not None and socio is not None:\n",
    "        # try any shared column\n",
    "        shared = set(merged.columns).intersection(set(socio.columns))\n",
    "        if shared:\n",
    "            key = list(shared)[0]\n",
    "            merged = merged.merge(socio, on=key, how='left')\n",
    "    # attach edu (provinsi) if possible\n",
    "    if merged is not None and edu is not None and 'provinsi' in edu.columns:\n",
    "        merged = merged.merge(edu, on='provinsi', how='left')\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e953351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataframe shape: None\n"
     ]
    }
   ],
   "source": [
    "df = unify_and_merge(poverty, socio, edu)\n",
    "print(\"Merged dataframe shape:\", df.shape if df is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd4d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m c\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m target_col \u001b[38;5;241m=\u001b[39m detect_target_column(df)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuto-detected target column:\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_col)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m, in \u001b[0;36mdetect_target_column\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_target_column\u001b[39m(df):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      3\u001b[0m         key \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkemiskin\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoverty\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtingkat\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "def detect_target_column(df):\n",
    "    for c in df.columns:\n",
    "        key = c.lower()\n",
    "        if 'kemiskin' in key or 'poverty' in key or 'tingkat' in key or 'status' in key:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "target_col = detect_target_column(df)\n",
    "print(\"Auto-detected target column:\", target_col)\n",
    "\n",
    "if target_col is None:\n",
    "    print(\"==> Edit variable target_col manually. Contoh: target_col = 'tingkat_kemiskinan'\")\n",
    "    print(\"Available columns:\", df.columns.tolist()[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03502d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7094e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
